/**
 * LLM Coherence Checker - Utilise un mod√®le local (Ollama) pour analyser la coh√©rence
 *
 * Ce service formate un voyage en texte lisible et demande √† un LLM
 * si le planning est coh√©rent (horaires, encha√Ænements, logique).
 *
 * N√©cessite Ollama en local: https://ollama.ai
 * Installer: curl -fsSL https://ollama.ai/install.sh | sh
 * Lancer un mod√®le: ollama run llama3.2 (ou mistral, phi3, etc.)
 */

import { Trip, TripDay, TripItem } from '../types';

// Configuration Ollama
const OLLAMA_URL = process.env.OLLAMA_URL || 'http://localhost:11434';
const OLLAMA_MODEL = process.env.OLLAMA_MODEL || 'llama3.2:3b';

export interface LLMCoherenceResult {
  isCoherent: boolean;
  issues: string[];
  suggestions: string[];
  rawResponse: string;
  confidence: 'high' | 'medium' | 'low';
  model: string;
}

/**
 * Formate un voyage en texte lisible pour le LLM
 */
export function formatTripForLLM(trip: Trip): string {
  const lines: string[] = [];

  lines.push(`=== VOYAGE: ${trip.preferences.origin} ‚Üí ${trip.preferences.destination} ===`);
  lines.push(`Date de d√©part: ${trip.preferences.startDate}`);
  lines.push(`Dur√©e: ${trip.preferences.durationDays} jours`);
  lines.push(`Voyageurs: ${trip.preferences.groupSize} personne(s)`);
  lines.push('');

  for (const day of trip.days) {
    lines.push(`--- JOUR ${day.dayNumber} (${formatDate(day.date)}) ---`);

    // Trier les items par heure de d√©but
    const sortedItems = [...day.items].sort((a, b) => {
      return parseTime(a.startTime) - parseTime(b.startTime);
    });

    for (const item of sortedItems) {
      const icon = getItemIcon(item.type);
      const duration = calculateDuration(item.startTime, item.endTime);
      lines.push(`  ${item.startTime}-${item.endTime} ${icon} ${item.title} (${duration})`);

      // Ajouter des d√©tails pour certains types
      if (item.type === 'flight') {
        lines.push(`    ‚Üí Transport a√©rien`);
      } else if (item.type === 'transport' && item.title.toLowerCase().includes('train')) {
        lines.push(`    ‚Üí Transport ferroviaire`);
      } else if (item.type === 'hotel') {
        lines.push(`    ‚Üí H√©bergement - Check-in`);
      } else if (item.type === 'checkout') {
        lines.push(`    ‚Üí H√©bergement - Check-out`);
      }
    }

    lines.push('');
  }

  return lines.join('\n');
}

/**
 * Analyse la coh√©rence d'un voyage via Ollama
 */
export async function checkCoherenceWithLLM(trip: Trip): Promise<LLMCoherenceResult> {
  const formattedTrip = formatTripForLLM(trip);

  const prompt = `Tu es un expert en planification de voyages. Analyse ce planning de voyage et v√©rifie sa COH√âRENCE LOGIQUE.

${formattedTrip}

V√©rifie les points suivants:
1. HORAIRES: Les heures sont-elles valides (entre 00:00 et 23:59)?
2. CHEVAUCHEMENTS: Y a-t-il des activit√©s qui se chevauchent?
3. S√âQUENCE LOGIQUE:
   - Jour d'arriv√©e: le vol/train arrive-t-il AVANT les activit√©s touristiques?
   - Jour de d√©part: le check-out est-il AVANT le transfert vers l'a√©roport/gare?
4. TEMPS DE TRAJET: Y a-t-il assez de temps entre les activit√©s pour se d√©placer?
5. REPAS: Petit-d√©jeuner le matin, d√©jeuner le midi, d√Æner le soir?
6. ACTIVIT√âS: Peut-on visiter une attraction AVANT d'√™tre arriv√© √† destination?

R√©ponds UNIQUEMENT au format JSON suivant (pas de texte avant ou apr√®s):
{
  "coherent": true/false,
  "issues": ["liste des probl√®mes d√©tect√©s"],
  "suggestions": ["liste de suggestions pour am√©liorer"],
  "confidence": "high/medium/low"
}`;

  try {
    const response = await callOllama(prompt);
    return parseOllamaResponse(response);
  } catch (error) {
    console.error('[LLMCoherenceChecker] Erreur Ollama:', error);
    return {
      isCoherent: true, // Par d√©faut, on consid√®re coh√©rent si Ollama n'est pas disponible
      issues: [],
      suggestions: ['Impossible de v√©rifier avec le LLM: ' + (error as Error).message],
      rawResponse: '',
      confidence: 'low',
      model: OLLAMA_MODEL,
    };
  }
}

/**
 * Appelle l'API Ollama
 */
async function callOllama(prompt: string): Promise<string> {
  const response = await fetch(`${OLLAMA_URL}/api/generate`, {
    method: 'POST',
    headers: {
      'Content-Type': 'application/json',
    },
    body: JSON.stringify({
      model: OLLAMA_MODEL,
      prompt,
      stream: false,
      options: {
        temperature: 0.1, // R√©ponses plus d√©terministes
        num_predict: 1000,
      },
    }),
  });

  if (!response.ok) {
    throw new Error(`Ollama HTTP error: ${response.status} ${response.statusText}`);
  }

  const data = await response.json();
  return data.response || '';
}

/**
 * Parse la r√©ponse JSON du LLM
 */
function parseOllamaResponse(response: string): LLMCoherenceResult {
  try {
    // Extraire le JSON de la r√©ponse (le LLM peut ajouter du texte avant/apr√®s)
    const jsonMatch = response.match(/\{[\s\S]*\}/);
    if (!jsonMatch) {
      console.warn('[LLMCoherenceChecker] Pas de JSON trouv√© dans la r√©ponse');
      return createFallbackResult(response);
    }

    const parsed = JSON.parse(jsonMatch[0]);

    return {
      isCoherent: parsed.coherent === true,
      issues: Array.isArray(parsed.issues) ? parsed.issues : [],
      suggestions: Array.isArray(parsed.suggestions) ? parsed.suggestions : [],
      rawResponse: response,
      confidence: parsed.confidence || 'medium',
      model: OLLAMA_MODEL,
    };
  } catch (error) {
    console.warn('[LLMCoherenceChecker] Erreur parsing JSON:', error);
    return createFallbackResult(response);
  }
}

/**
 * Cr√©e un r√©sultat de fallback si le parsing √©choue
 */
function createFallbackResult(response: string): LLMCoherenceResult {
  // Analyse basique du texte pour d√©tecter des probl√®mes
  const lowerResponse = response.toLowerCase();
  const hasIssues =
    lowerResponse.includes('incoh√©rent') ||
    lowerResponse.includes('probl√®me') ||
    lowerResponse.includes('erreur') ||
    lowerResponse.includes('impossible') ||
    lowerResponse.includes('chevauchement');

  return {
    isCoherent: !hasIssues,
    issues: hasIssues ? ['Probl√®mes d√©tect√©s (voir rawResponse)'] : [],
    suggestions: [],
    rawResponse: response,
    confidence: 'low',
    model: OLLAMA_MODEL,
  };
}

// ============================================
// FONCTIONS UTILITAIRES
// ============================================

function formatDate(date: Date): string {
  return new Date(date).toLocaleDateString('fr-FR', {
    weekday: 'long',
    day: 'numeric',
    month: 'long',
  });
}

function parseTime(time: string): number {
  const [hours, minutes] = time.split(':').map(Number);
  return hours * 60 + minutes;
}

function calculateDuration(start: string, end: string): string {
  const startMin = parseTime(start);
  const endMin = parseTime(end);
  const duration = endMin - startMin;

  if (duration < 60) {
    return `${duration}min`;
  }

  const hours = Math.floor(duration / 60);
  const mins = duration % 60;
  return mins > 0 ? `${hours}h${mins}` : `${hours}h`;
}

function getItemIcon(type: string): string {
  switch (type) {
    case 'flight':
      return '‚úàÔ∏è';
    case 'transport':
      return 'üöó';
    case 'hotel':
      return 'üè®';
    case 'checkout':
      return 'üè®';
    case 'checkin':
      return 'üìã';
    case 'activity':
      return 'üéØ';
    case 'restaurant':
      return 'üçΩÔ∏è';
    case 'parking':
      return 'üÖøÔ∏è';
    default:
      return 'üìç';
  }
}

/**
 * V√©rifie si Ollama est disponible
 */
export async function isOllamaAvailable(): Promise<boolean> {
  try {
    const response = await fetch(`${OLLAMA_URL}/api/tags`, {
      method: 'GET',
      signal: AbortSignal.timeout(2000), // 2s timeout
    });
    return response.ok;
  } catch {
    return false;
  }
}

/**
 * Liste les mod√®les disponibles sur Ollama
 */
export async function listOllamaModels(): Promise<string[]> {
  try {
    const response = await fetch(`${OLLAMA_URL}/api/tags`);
    if (!response.ok) return [];

    const data = await response.json();
    return data.models?.map((m: { name: string }) => m.name) || [];
  } catch {
    return [];
  }
}
